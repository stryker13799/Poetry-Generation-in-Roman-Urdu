{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ali Kamal\n",
    "# i191865@nu.edu.pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import random\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gets poetry text file as input and returns a \n",
    "stripped list containing the text\n",
    "\"\"\"\n",
    "def read(f):\n",
    "    with open(f) as file:\n",
    "        #lines = [\"[START] {0} [END]\".format(line.rstrip()) for line in file.readlines() if line.strip()]\n",
    "        lines = [(line.rstrip()) for line in file.readlines() if line.strip()]\n",
    "    return [ele for ele in lines if all(ch not in ele for ch in '?')]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Uses Regex to convert a string to upper case\n",
    "\"\"\"\n",
    "upper_case = re.compile(r'((?<=[\\.\\?!]\\s)(\\w+)|(^\\w+))')\n",
    "def capital(string):\n",
    "    return(string.group().capitalize())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Gets a list of text as input, and returns\n",
    "ngram (bigram,trigram,4-gram etc) depending\n",
    "on input parameters\n",
    "\"\"\"\n",
    "def get_ngrams(doc,n=2):\n",
    "    if not isinstance(n, int):\n",
    "        raise Exception(f\"Ngram argument {n=} must be an integer type\")\n",
    "    if (n<1):\n",
    "        raise Exception(f\"Ngram argument {n=} must >=1\")\n",
    "    result = list()\n",
    "    sentence=list()\n",
    "    sentence = (n-1)*['[START]']\n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            sentence.append(token)\n",
    "    sentence+=['[END]']\n",
    "    for word in range(len(sentence) - (n-1)):\n",
    "        words=[]\n",
    "        for i in range(n):\n",
    "            try:\n",
    "                words.append(sentence[word+i].text)\n",
    "            except AttributeError:\n",
    "                words.append(sentence[word+i])\n",
    "        result.append(words)\n",
    "    return result\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Gets a list of ngrams and returns \n",
    "a list dictionary with ngrams as keys\n",
    "and their counts in the corpus as values\n",
    "\"\"\"\n",
    "def get_ngram_counts(ngrams): \n",
    "    ngram_dict = {}\n",
    "    for stanza in ngrams:\n",
    "        for ngram in stanza:\n",
    "            ngram_str=' '.join(map(str,ngram))\n",
    "            ngram_dict[ngram_str]=ngram_dict[ngram_str]+1 if ngram_str in ngram_dict else 1\n",
    "    if(np.shape(ngrams[0][0])==(1,)):\n",
    "        ngram_dict['[START]']=ngram_dict['[END]']\n",
    "    return ngram_dict\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Gets a list of ngrams and returns \n",
    "a list dictionary with ngrams as keys\n",
    "and their counts in the corpus as values\n",
    "\"\"\"\n",
    "def ngram_prob(ngrams,n_minus1_grams,vocab,n=2):\n",
    "    ngram_dict={}\n",
    "    for i in ngrams.keys():\n",
    "        i_str=''.join(map(str,i))\n",
    "        prev_ngram_str=' '.join(map(str,i.split()[0:n-1]))\n",
    "        try: #bigrams\n",
    "        #Calculating ngram conditional probabiltiy and applying laplace smoothing\n",
    "            ngram_dict[i_str]=(ngrams[i_str]+1)/(n_minus1_grams[prev_ngram_str]+len(vocab)) \n",
    "        except: #trigrams\n",
    "            prev_ngram_str=' '.join(map(str,i.split()[1:n]))\n",
    "            ngram_dict[i_str]=(ngrams[i_str]+1)/(n_minus1_grams[prev_ngram_str]+len(vocab)) \n",
    "    return ngram_dict\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Gets vocabulary size (number of unique words)\n",
    "of a corpus. Used for laplace smoothing\n",
    "\"\"\"\n",
    "def get_unique_words(corpus):\n",
    "    vocab_set = set()\n",
    "    for verse in corpus:\n",
    "        words=verse.split()\n",
    "        for word in words:\n",
    "            if word not in vocab_set:\n",
    "                vocab_set.add(word)\n",
    "            else:\n",
    "                pass\n",
    "    return vocab_set\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Returns a sorted ngram dictonary(in descending order of their probability),\n",
    "based on a prior key (e.g if input is \"kiya\", outputs dictionary of ngrams\n",
    "containing, but not limited to, \"kiya\", with their probabilities as well)\n",
    "\"\"\"\n",
    "def getkey(k,dic):\n",
    "    dic=dict(sorted(dic.items(), key=lambda x:x[1],reverse=True))\n",
    "    return (dict([(key,value) for key, value in dic.items() if k in key]))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Returns an ngram with the highest probability \n",
    "from an ngram dictionary\n",
    "\"\"\"\n",
    "def get_highest_prob_word(word,ngrams,c=1):\n",
    "    high_prob_words=getkey(word,ngrams)\n",
    "    list_high_prob_words=list(high_prob_words)\n",
    "    \n",
    "    curr_word=''\n",
    "    try:\n",
    "        curr_word=list_high_prob_words[0]\n",
    "        while('[END]' in curr_word or '[START]' in curr_word):\n",
    "            curr_word=list_high_prob_words[c]\n",
    "            c+=1\n",
    "    except:\n",
    "        pass\n",
    "    return curr_word\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Returns an ngram with the highest probability \n",
    "from an ngram dictionary, but looks both\n",
    "forward and backwards ways, and returns \n",
    "whichever one has the highest probability\n",
    "\"\"\"\n",
    "def get_highest_prob_bidirectional(word,ngrams,c=1):\n",
    "    high_prob_words=getkey(word+\" \",ngrams)\n",
    "    list_high_prob_words=list(high_prob_words)\n",
    "    \n",
    "    rev_high_prob_words=getkey(\" \"+word,ngrams)\n",
    "    rev_list_high_prob_words=list(rev_high_prob_words)\n",
    "    \n",
    "    curr_word=''\n",
    "    curr_word_prev=''\n",
    "    try:\n",
    "        curr_word=list_high_prob_words[0]\n",
    "        curr_word_prev= rev_list_high_prob_words[0]\n",
    "        \n",
    "        if high_prob_words[curr_word]>=rev_high_prob_words[curr_word_prev]:\n",
    "            chosen_word=curr_word\n",
    "            flag=0\n",
    "        else:\n",
    "            chosen_word=curr_word_prev\n",
    "            flag=1\n",
    "        while('[END]' in chosen_word or '[START]' in chosen_word):\n",
    "            curr_word=list_high_prob_words[c]\n",
    "            curr_word_prev= rev_list_high_prob_words[c]\n",
    "            if high_prob_words[curr_word]>=rev_high_prob_words[curr_word_prev]:\n",
    "                chosen_word=curr_word\n",
    "                flag=0\n",
    "            else:\n",
    "                chosen_word=curr_word_prev\n",
    "                flag=1\n",
    "            c+=1\n",
    "    except:\n",
    "        pass\n",
    "    chosen_word=chosen_word.split()[-1] if not flag else chosen_word.split()[0]\n",
    "    return chosen_word\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This is soundex function taken from the Jellyfish\n",
    "package (https://github.com/jamesturk/jellyfish/blob/main/jellyfish/_jellyfish.py)\n",
    "All credits to the original authors jamesturk, juliangilbey et al.\n",
    "This basically returns the rhyming signature of a word, which we \n",
    "will later use to predict ending rhyming words for our 'ghazal'\n",
    "\"\"\"\n",
    "def rhyme_signature(s):\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = s.upper()\n",
    "    replacements = (\n",
    "        (\"BFPV\", \"1\"),\n",
    "        (\"CGJKQSXZ\", \"2\"),\n",
    "        (\"DT\", \"3\"),\n",
    "        (\"L\", \"4\"),\n",
    "        (\"MN\", \"5\"),\n",
    "        (\"R\", \"6\"),\n",
    "    )\n",
    "    result = [s[0]]\n",
    "    count = 1\n",
    "    #find replacment for first character\n",
    "    for lset, sub in replacements:\n",
    "        if s[0] in lset:\n",
    "            last = sub\n",
    "            break\n",
    "    else:\n",
    "        last = None\n",
    "    for letter in s[1:]:\n",
    "        for lset, sub in replacements:\n",
    "            if letter in lset:\n",
    "                if sub != last:\n",
    "                    result.append(sub)\n",
    "                    count += 1\n",
    "                last = sub\n",
    "                break\n",
    "        else:\n",
    "            if letter != \"H\" and letter != \"W\":\n",
    "                #leave last alone if middle letter is H or W\n",
    "                last = None\n",
    "        if count == 4:\n",
    "            break\n",
    "    result += \"0\" * (4 - count)\n",
    "    return \"\".join(result)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Driver function to check whether two \n",
    "words rhyme, utilizing our previous\n",
    "rhyme_signature function\n",
    "\"\"\"\n",
    "def is_rhyming(w1,w2):\n",
    "    w1s=rhyme_signature(w1)\n",
    "    w2s=rhyme_signature(w2)\n",
    "    \n",
    "    return True if (w1s[1]==w2s[1] and w1s[2]==w2s[2] and w1s[3]==w2s[3]) else False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main driver function which generates a verse,\n",
    "given ngram probability dictionary, ngram length,\n",
    "and whether to generate standard or backward n-gram model\n",
    "\"\"\"\n",
    "def gen_verse(ngrams,ngramlength,generated_verse,curr_verse_no,reverse=False):\n",
    "    if(ngramlength!=2 and ngramlength!=3):\n",
    "        raise Exception(\"Only works on bigrams and trigrams (n=2 or n=3)\")\n",
    "    verse=[]\n",
    "    n=random.randint(6,8)\n",
    "    for i in range(n):\n",
    "        if(i==0): #START\n",
    "            start_word=getkey('[START]',ngrams) if not reverse else getkey('[END]',ngrams)\n",
    "            verse.append(\"\".join(re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\",random.choices(list(start_word.keys()), weights=start_word.values(), k=1)[0]).split()[-1]))\n",
    "        elif i==n-1: #END\n",
    "            end_word=getkey('[END]',ngrams) if not reverse else getkey('[START]',ngrams)\n",
    "            end_word_cleaned=\"\".join(re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", random.choices(list(end_word.keys()), weights=end_word.values(), k=1)[0]).split()[-1])\n",
    "            if(curr_verse_no%2==0):\n",
    "                c=0\n",
    "                #Attempts to create rhyming stanza, as stated in the BONUS task\n",
    "                while not is_rhyming(generated_verse[curr_verse_no-2].split()[-1],end_word_cleaned):\n",
    "                    try:\n",
    "                        end_word_cleaned=\"\".join(re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", random.choices(list(end_word.keys()), weights=end_word.values(), k=1)[0]).split()[-1])\n",
    "                    except:\n",
    "                        end_word=getkey('[END]',ngrams) if not reverse else getkey('[START]',ngrams)\n",
    "                        end_word_cleaned=\"\".join(re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", random.choices(list(end_word.keys()), weights=end_word.values(), k=1)[0]).split()[-1])\n",
    "                        break\n",
    "                    if(c==20):\n",
    "                        break\n",
    "            verse.append(end_word_cleaned)\n",
    "        else:\n",
    "            #try:\n",
    "            if ngramlength==2 or i<=2:\n",
    "                mid_word=get_highest_prob_word(verse[i-1]+\" \",ngrams)\n",
    "            else:\n",
    "                prec_word=verse[i-1]+\" \" +verse[i-2]\n",
    "                mid_word=get_highest_prob_word(prec_word+\" \",ngrams)\n",
    "            try:\n",
    "                mid_word=mid_word.split()[-1]\n",
    "            except:\n",
    "                while((len(mid_word)==0) or ('[START]' in mid_word) or ('[END]' in mid_word)):\n",
    "                    mid_word=(random.choices(list(ngrams.keys()), weights=ngrams.values(), k=1)[0]).split()[-1]\n",
    "            counter=0\n",
    "            while((len(mid_word)==0) or ('[START]' in mid_word) or ('[END]' in mid_word)):\n",
    "                if(counter>5):\n",
    "                    mid_word=(random.choices(list(ngrams.keys()), weights=ngrams.values(), k=1)[0]).split()[-1]\n",
    "                    break\n",
    "                if ngramlength==2 or i<=2:\n",
    "                    mid_word=get_highest_prob_word(verse[i-1]+\" \",ngrams)\n",
    "                else:\n",
    "                    prec_word=verse[i-1]+\" \" +verse[i-2]\n",
    "                    mid_word=get_highest_prob_word(prec_word+\" \",ngrams)\n",
    "                counter+=1\n",
    "            mid_word=mid_word.split()[-1]\n",
    "            verse.append(mid_word)\n",
    "    if(reverse):\n",
    "        verse[0], verse[-1] = verse[-1], verse[0]\n",
    "    return \" \".join(verse) if not reverse else \" \".join([i for i in verse[::-1]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Main driver function which generates a verse,\n",
    "using bidirectional bigram model\n",
    "\"\"\"\n",
    "def bidirectional_bigram(ngrams,ngramlength,generated_verse,curr_verse_no):\n",
    "    if(ngramlength!=2):\n",
    "        raise Exception(\"Only works on bigrams and trigrams (n=2 or n=3)\")\n",
    "    verse=[]\n",
    "    n=random.randint(6,8)\n",
    "    for i in range(n):\n",
    "        if(i==0): #START\n",
    "            start_word=getkey('[START]',ngrams)\n",
    "            verse.append(\"\".join(re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\",random.choices(list(start_word.keys()), weights=start_word.values(), k=1)[0]).split()[-1]))\n",
    "        elif i==n-1: #END\n",
    "            end_word=getkey('[END]',ngrams)\n",
    "            end_word_cleaned=\"\".join(re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", random.choices(list(end_word.keys()), weights=end_word.values(), k=1)[0]).split()[-1])\n",
    "            if(curr_verse_no%2==0):\n",
    "                c=0\n",
    "                #Attempts to create rhyming stanza, as stated in the BONUS task\n",
    "                while not is_rhyming(generated_verse[curr_verse_no-2].split()[-1],end_word_cleaned):\n",
    "                    try:\n",
    "                        end_word_cleaned=\"\".join(re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", random.choices(list(end_word.keys()), weights=end_word.values(), k=1)[0]).split()[-1])\n",
    "                    except:\n",
    "                        end_word=getkey('[END]',ngrams) if not reverse else getkey('[START]',ngrams)\n",
    "                        end_word_cleaned=\"\".join(re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", random.choices(list(end_word.keys()), weights=end_word.values(), k=1)[0]).split()[-1])\n",
    "                    if(c==20):\n",
    "                        break\n",
    "            verse.append(end_word_cleaned)\n",
    "        else:\n",
    "            mid_word=get_highest_prob_bidirectional(verse[i-1],ngrams)\n",
    "            counter=0\n",
    "            while((len(mid_word)==0) or ('[START]' in mid_word) or ('[END]' in mid_word)):\n",
    "                if(counter>5):\n",
    "                    mid_word=(random.choices(list(ngrams.keys()), weights=ngrams.values(), k=1)[0]).split()[-1]\n",
    "                    break\n",
    "                mid_word=get_highest_prob_bidirectional(verse[i-1],ngrams)\n",
    "                counter+=1\n",
    "                mid_word=mid_word.split()[-1]\n",
    "            verse.append(mid_word)    \n",
    "    return \" \".join(verse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# Reading corpus and building ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry=read(\"poetry_english.txt\")\n",
    "unique_vocab=get_unique_words(poetry)\n",
    "\n",
    "unigrams=[]\n",
    "bigrams=[]\n",
    "trigrams=[]\n",
    "for i in poetry:\n",
    "    unigrams.append(get_ngrams(nlp(i),1))\n",
    "    bigrams.append(get_ngrams(nlp(i)))\n",
    "    trigrams.append(get_ngrams(nlp(i),3))\n",
    "\n",
    "\n",
    "unigrams_count=get_ngram_counts(unigrams)\n",
    "bigrams_count=get_ngram_counts(bigrams)\n",
    "trigrams_count=get_ngram_counts(trigrams)\n",
    "\n",
    "bigrams_prob=ngram_prob(bigrams_count,unigrams_count,unique_vocab,2)\n",
    "trigrams_prob=ngram_prob(trigrams_count,bigrams_count,unique_vocab,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanzas=7\n",
    "verse=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard n-gram Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dhamki mein bhi nahi aati hai ke gaye\n",
      "Yeh baat par nahi aati hai tha\n",
      "\n",
      "\n",
      "Mohammad bhi nahi aati hai ke liye Aziz\n",
      "Ik baar hota hai ke liye hum bakhash\n",
      "\n",
      "\n",
      "Mohammad bhi nahi aati hai ghalib\n",
      "Aayi ke liye hum ne chaha tha ghalib\n",
      "\n",
      "\n",
      "Beddad dost naaseh ne chaha tha ke bani\n",
      "Ghuncha phir laga ke liye hum mein\n",
      "\n",
      "\n",
      "Nah sun hwa hai ke liye dalie\n",
      "Rakh kar raha hai ke liye hum qaail\n",
      "\n",
      "\n",
      "Pucho to kya hai ke hoga\n",
      "Shairi unki adab hon mein bhi nahi likhwaye\n",
      "\n",
      "\n",
      "Yahan ke liye hum ne ghalib\n",
      "Taaqat guftaar aur bhi nahi ghalib\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forward_bigram_ghazal=[]\n",
    "for i in range(1,(stanzas*verse)+1):\n",
    "    forward_bigram_ghazal.append(upper_case.sub(capital,(gen_verse(bigrams_prob,2,forward_bigram_ghazal,i))))    \n",
    "for idx,i in enumerate(forward_bigram_ghazal):\n",
    "    print(i)\n",
    "    if(idx%2):\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aam bhi hain thi mein visale\n",
      "Baat par hwa o ishhq nikla\n",
      "\n",
      "\n",
      "Moay deedaa dil hui mujh par aaya\n",
      "Subha Marghoob buut siya to kya\n",
      "\n",
      "\n",
      "Bas gashta wafa kidhar hain tairay ho\n",
      "Zuba ki dawa bah dushman ke ko se\n",
      "\n",
      "\n",
      "Parhnay ke liya ke saamna apne hai\n",
      "Barg Gul gird wagerna Daagh nahi\n",
      "\n",
      "\n",
      "Hi nah hwa maang kya khula\n",
      "Wahn aarai ko to koi ko ka qaail\n",
      "\n",
      "\n",
      "Sheree sukhan se khaak pouchon mujhe\n",
      "Rasam barham fanaa se ghaafil saaz\n",
      "\n",
      "\n",
      "Koi dil jigar rawish jis nahi dosh Rubab\n",
      "Beddad dost naaseh lagey jo barq bahar shabab\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forward_trigram_ghazal=[]\n",
    "for i in range(1,(stanzas*verse)+1):\n",
    "    forward_trigram_ghazal.append(upper_case.sub(capital,(gen_verse(trigrams_prob,3,forward_trigram_ghazal,i)))) \n",
    "for idx,i in enumerate(forward_trigram_ghazal):\n",
    "    print(i)\n",
    "    if(idx%2):\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward n-gram Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gayi hum liye ke hai juz\n",
      "Hai tha chaha ne hum liye ke juz\n",
      "\n",
      "\n",
      "Se nahi bhi mein guzar tre\n",
      "Hwa chaha ne hum liye ke hai tri\n",
      "\n",
      "\n",
      "Doori ke hai aati nahi bhi mein ik\n",
      "Chahiye ke hai hota baar ik ik\n",
      "\n",
      "\n",
      "Ghalib nayam aish terhan ki duniya\n",
      "Gaya ke hai kya to pion\n",
      "\n",
      "\n",
      "Bas hum liye ke hai khoo go\n",
      "Haal tha chaha ne hum liye e to\n",
      "\n",
      "\n",
      "Hum hum liye ke tha chaha ne bharam\n",
      "Paaya hai aati nahi bhi mein ko Mehram\n",
      "\n",
      "\n",
      "Nikla nahi bhi woh so marey\n",
      "Sunaoun hum liye e hasrat tri\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backward_bigram_ghazal=[]\n",
    "for i in range(1,(stanzas*verse)+1):\n",
    "    backward_bigram_ghazal.append(upper_case.sub(capital,(gen_verse(bigrams_prob,2,backward_bigram_ghazal,i,reverse=True))))   \n",
    "for idx,i in enumerate(backward_bigram_ghazal):\n",
    "    print(i)\n",
    "    if(idx%2):\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharminda kareem qayamat tha nah maienay aati\n",
      "Sharminda se dar kehte nah maienay deta\n",
      "\n",
      "\n",
      "Par ghareeb yeh dil hai hwa karta\n",
      "Tak mudda hi jo hai hai baqi parda\n",
      "\n",
      "\n",
      "Umeed ke kar ne se ne\n",
      "Yaktaa Gul ke masti nah ulajh ke\n",
      "\n",
      "\n",
      "Tha zarraa bhar bhar liya ke hai\n",
      "Roshni izr bhi o Danish taa\n",
      "\n",
      "\n",
      "Sahi mansoob o mann raha hain bhi zulm\n",
      "Maloom mahaal par usay dikhavay ke is ilm\n",
      "\n",
      "\n",
      "Doori he ho ki assar be ki\n",
      "Tha kefiyat aur dekh same liya ke woh\n",
      "\n",
      "\n",
      "Nahi kaaba tha o nahi mein dardi\n",
      "Kya sahi hai to hota dard\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backward_trigram_ghazal=[]\n",
    "for i in range(1,(stanzas*verse)+1):\n",
    "    backward_trigram_ghazal.append(upper_case.sub(capital,(gen_verse(trigrams_prob,3,backward_trigram_ghazal,i,reverse=True))))   \n",
    "for idx,i in enumerate(backward_trigram_ghazal):\n",
    "    print(i)\n",
    "    if(idx%2):\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# Bidirectional Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warna yaan warna yaan warna yaan pewand\n",
      "Mein hon mein hon mein hon wandi\n",
      "\n",
      "\n",
      "Ishhq ko uss ko uss ko lolaak\n",
      "Dozakh ko uss ko uss ko talak\n",
      "\n",
      "\n",
      "Mein hon mein hon mein hon ko\n",
      "Kyun nah sun hwa sun hwa sun liye\n",
      "\n",
      "\n",
      "Hmm sath piyay sath piyay diya\n",
      "Qanaat nah sun hwa sun hai\n",
      "\n",
      "\n",
      "Nah sun hwa sun hwa sun hwa kshad\n",
      "Nah sun hwa sun hwa sayyad\n",
      "\n",
      "\n",
      "Khoo hai ke liye ke hoga\n",
      "Fiqiya shehar mein hon mein hon jisay\n",
      "\n",
      "\n",
      "Azad ajab azad ajab azad ajab azad shama\n",
      "Kharaaj diyaa viran diyaa viran hain\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bidirectional_bigram_ghazal=[]\n",
    "for i in range(1,(stanzas*verse)+1):\n",
    "    bidirectional_bigram_ghazal.append(upper_case.sub(capital,(bidirectional_bigram(bigrams_prob,2,bidirectional_bigram_ghazal,i))))    \n",
    "for idx,i in enumerate(bidirectional_bigram_ghazal):\n",
    "    print(i)\n",
    "    if(idx%2):\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <br>\n",
    "### Comparing output of Bidirectional Bigram Model and Trigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aam bhi hain thi mein visale\n",
      "Baat par hwa o ishhq nikla\n",
      "\n",
      "\n",
      "Moay deedaa dil hui mujh par aaya\n",
      "Subha Marghoob buut siya to kya\n",
      "\n",
      "\n",
      "Bas gashta wafa kidhar hain tairay ho\n",
      "Zuba ki dawa bah dushman ke ko se\n",
      "\n",
      "\n",
      "Parhnay ke liya ke saamna apne hai\n",
      "Barg Gul gird wagerna Daagh nahi\n",
      "\n",
      "\n",
      "Hi nah hwa maang kya khula\n",
      "Wahn aarai ko to koi ko ka qaail\n",
      "\n",
      "\n",
      "Sheree sukhan se khaak pouchon mujhe\n",
      "Rasam barham fanaa se ghaafil saaz\n",
      "\n",
      "\n",
      "Koi dil jigar rawish jis nahi dosh Rubab\n",
      "Beddad dost naaseh lagey jo barq bahar shabab\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx,i in enumerate(forward_trigram_ghazal):\n",
    "    print(i)\n",
    "    if(idx%2):\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bidirectional Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warna yaan warna yaan warna yaan pewand\n",
      "Mein hon mein hon mein hon wandi\n",
      "\n",
      "\n",
      "Ishhq ko uss ko uss ko lolaak\n",
      "Dozakh ko uss ko uss ko talak\n",
      "\n",
      "\n",
      "Mein hon mein hon mein hon ko\n",
      "Kyun nah sun hwa sun hwa sun liye\n",
      "\n",
      "\n",
      "Hmm sath piyay sath piyay diya\n",
      "Qanaat nah sun hwa sun hai\n",
      "\n",
      "\n",
      "Nah sun hwa sun hwa sun hwa kshad\n",
      "Nah sun hwa sun hwa sayyad\n",
      "\n",
      "\n",
      "Khoo hai ke liye ke hoga\n",
      "Fiqiya shehar mein hon mein hon jisay\n",
      "\n",
      "\n",
      "Azad ajab azad ajab azad ajab azad shama\n",
      "Kharaaj diyaa viran diyaa viran hain\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx,i in enumerate(bidirectional_bigram_ghazal):\n",
    "    print(i)\n",
    "    if(idx%2):\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both Bidirectional Bigram and Trigram Models produce a similar output, acceptable output. Both are also attempting to preserve the rhyming structure of the stanzas that I implemented"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
